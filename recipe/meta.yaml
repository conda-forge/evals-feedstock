{% set name = "evals" %}
{% set version = "1.0.3.post1" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/evals-{{ version }}.tar.gz
  sha256: d24f525e0051d48662f38f4f1216d61ea0079df5a5ec0ee5582c28b7eeed4661

build:
  entry_points:
    - oaieval = evals.cli.oaieval:main
    - oaievalset = evals.cli.oaievalset:main
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv
  number: 0

requirements:
  host:
    - python >=3.9
    - pip
  run:
    - python >=3.9
    - mypy
    - openai >=0.27.2
    - tiktoken
    - blobfile
    - backoff
    - numpy
    - snowflake-connector-python
    - pandas
    - fire
    - pydantic
    - tqdm
    - nltk
    - filelock
    - mock
    - langdetect
    - termcolor
    - lz4
    - pyzstd
    - pyyaml
    - sacrebleu
    - matplotlib-base
    - setuptools-scm

test:
  imports:
    - evals
  commands:
    - pip check
    - oaieval --help
    - oaievalset --help
  requires:
    - pip

about:
  home: https://github.com/openai/evals
  summary: Evals is a framework for evaluating OpenAI models and an open-source registry of benchmarks.
  license: MIT
  license_file: LICENSE

extra:
  recipe-maintainers:
    - BastianZim
